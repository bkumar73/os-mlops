{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adee1ac-3a09-47eb-bdc9-94c7b0dd5358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import environ\n",
    "\n",
    "from boto3 import client\n",
    "from numpy import mean, number\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, to_numeric\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import DMatrix, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e880f01-47b3-4895-8b87-5a5cba14c546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_endpoint_url = f\"https://{environ.get('AWS_S3_ENDPOINT')}\"\n",
    "s3_access_key = environ.get('AWS_ACCESS_KEY_ID')\n",
    "s3_secret_key = environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "s3_bucket_name = environ.get('AWS_S3_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a0685-6b1e-45aa-a6c5-dbc6185401ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Downloading data \"training-data.csv\" '\n",
    "      f'from bucket \"{s3_bucket_name}\" '\n",
    "      f'from S3 storage at {s3_endpoint_url}')\n",
    "\n",
    "s3_client = client(\n",
    "    's3', endpoint_url=s3_endpoint_url,\n",
    "    aws_access_key_id=s3_access_key, aws_secret_access_key=s3_secret_key\n",
    ")\n",
    "\n",
    "s3_client.download_file(\n",
    "    s3_bucket_name,\n",
    "    'BreastCancerWisconsinDataSet.csv',\n",
    "    './data/raw_data.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c7e10-a637-45d3-ab2b-5801d17bc1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Loading raw data.\")\n",
    "\n",
    "# Load the raw data\n",
    "data = read_csv(\"data/raw_data.csv\")\n",
    "\n",
    "# Display summary statistics similar to skim()\n",
    "print(data.describe(include='all'))\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "\n",
    "# Drop duplicate rows based on 'id' column\n",
    "data = data.drop_duplicates(subset='id')\n",
    "\n",
    "# Select specific columns\n",
    "columns_to_keep = [\n",
    "    'diagnosis',\n",
    "    'radius_mean',\n",
    "    'area_mean',\n",
    "    'radius_worst',\n",
    "    'area_worst',\n",
    "    'perimeter_worst',\n",
    "    'perimeter_mean'\n",
    "]\n",
    "data = data[columns_to_keep]\n",
    "\n",
    "# Convert all columns except 'diagnosis' to numeric\n",
    "cols_to_convert = data.columns.difference(['diagnosis'])\n",
    "data[cols_to_convert] = data[cols_to_convert].apply(\n",
    "    to_numeric, errors='coerce'\n",
    ")\n",
    "\n",
    "print(\"Data cleaning done, saving file.\")\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv(\"data/cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff992a14-e991-4b58-9080-e4807a2b6899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "seed(1)\n",
    "print(\"Set seed 1\")\n",
    "\n",
    "print(\"Load cleaned data\")\n",
    "data_cleaned = read_csv(\"data/cleaned_data.csv\")\n",
    "\n",
    "# Standardize the numeric columns\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = data_cleaned.select_dtypes(include=number).columns\n",
    "data_cleaned[numeric_cols] = scaler.fit_transform(data_cleaned[numeric_cols])\n",
    "\n",
    "print(\"Creating train and testing files\")\n",
    "# Use 70% of dataset as training set and remaining 30% as testing set\n",
    "train_set, test_set = train_test_split(\n",
    "    data_cleaned, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "print(\"Writing to csv files.\")\n",
    "train_set.to_csv(\"data/train.csv\", index=False)\n",
    "test_set.to_csv(\"data/test.csv\", index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4ec97-cade-4b9c-ba5a-4820a547a17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read environment variables\n",
    "max_depth = int(environ.get('max_depth', '10'))\n",
    "n_round = int(environ.get('n_round', '21'))\n",
    "early_stopping_rounds = int(environ.get('early_stopping_rounds', '3'))\n",
    "\n",
    "print('Loading training and test data')\n",
    "train_set = read_csv(\"data/train.csv\")\n",
    "test_set = read_csv(\"data/test.csv\")\n",
    "\n",
    "# Remove labels\n",
    "train_data = train_set.drop(columns=['diagnosis'])\n",
    "test_data = test_set.drop(columns=['diagnosis'])\n",
    "\n",
    "# Create targets\n",
    "train_label = train_set['diagnosis'].apply(lambda x: 1 if x == \"M\" else 0).values\n",
    "test_label = test_set['diagnosis'].apply(lambda x: 1 if x == \"M\" else 0).values\n",
    "\n",
    "# Convert to matrices\n",
    "train_matrix = train_data.values\n",
    "test_matrix = test_data.values\n",
    "\n",
    "# Create DMatrix\n",
    "dtrain = DMatrix(data=train_matrix, label=train_label)\n",
    "dtest = DMatrix(data=test_matrix, label=test_label)\n",
    "\n",
    "print('Training model...')\n",
    "breastcancer_model = train(\n",
    "    params={\n",
    "        'max_depth': max_depth,\n",
    "        'objective': 'binary:logistic',\n",
    "        'verbosity': 2,\n",
    "        'early_stopping_rounds': early_stopping_rounds\n",
    "    },\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=n_round,\n",
    "    evals=[(dtest, 'test')]\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "pred = breastcancer_model.predict(dtest)\n",
    "err = mean((pred > 0.5).astype(int) != test_label)\n",
    "print(f\"test-error= {err}\")\n",
    "\n",
    "print('Saving model')\n",
    "breastcancer_model.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed6ffd-36cc-4e1c-a0e3-b8d40ecd2a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%y%m%d%H%M')\n",
    "model_object_name = f'model-{timestamp}.bst'\n",
    "\n",
    "try:\n",
    "    s3_client.upload_file('model.bst', s3_bucket_name, model_object_name)\n",
    "except Exception:\n",
    "    print(f'S3 upload to bucket {s3_bucket_name} at {s3_endpoint_url} failed!')\n",
    "    raise\n",
    "print(f'model uploaded and available as \"{model_object_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d518714-65ae-4f23-80b8-88a0c77bec8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
