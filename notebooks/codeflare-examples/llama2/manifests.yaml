kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: models-cache
  annotations:
    pv.kubernetes.io/bind-completed: 'yes'
    pv.kubernetes.io/bound-by-controller: 'yes'
    volume.beta.kubernetes.io/storage-provisioner: openshift-storage.cephfs.csi.ceph.com
    volume.kubernetes.io/storage-provisioner: openshift-storage.cephfs.csi.ceph.com
  finalizers:
    - kubernetes.io/pvc-protection
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: ocs-storagecluster-cephfs
  volumeMode: Filesystem
---
kind: Secret
apiVersion: v1
metadata:
  name: ocp-login-secret
stringData:
  OCP_API_SERVER_URL: sha256~V05pfhY0c9spjrtGvyQErdhTVXQpHSK0Ix8OjoTeRWg
  OCP_TOKEN: https://api.cluster-cvx6l.cvx6l.sandbox399.opentlc.com:6443
---
apiVersion: workload.codeflare.dev/v1beta1
kind: AppWrapper
metadata:
  name: llamafinetunelora
spec:
  resources:
    GenericItems:
      - custompodresources:
          - limits:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 0
            replicas: 1
            requests:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 0
          - limits:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 1
            replicas: 1
            requests:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 1
        generictemplate:
          apiVersion: ray.io/v1alpha1
          kind: RayCluster
          metadata:
            labels:
              controller-tools.k8s.io: '1.0'
              workload.codeflare.dev/appwrapper: llamafinetunelora
            name: llamafinetunelora
            namespace: ray-demo
          spec:
            autoscalerOptions:
              idleTimeoutSeconds: 60
              imagePullPolicy: Always
              resources:
                limits:
                  cpu: 500m
                  memory: 512Mi
                requests:
                  cpu: 500m
                  memory: 512Mi
              upscalingMode: Default
            enableInTreeAutoscaling: false
            headGroupSpec:
              rayStartParams:
                block: 'true'
                dashboard-host: 0.0.0.0
                num-gpus: '0'
              serviceType: ClusterIP
              template:
                spec:
                  containers:
                    - env:
                        - name: MY_POD_IP
                          valueFrom:
                            fieldRef:
                              fieldPath: status.podIP
                        - name: RAY_USE_TLS
                          value: '0'
                        - name: RAY_TLS_SERVER_CERT
                          value: /home/ray/workspace/tls/server.crt
                        - name: RAY_TLS_SERVER_KEY
                          value: /home/ray/workspace/tls/server.key
                        - name: RAY_TLS_CA_CERT
                          value: /home/ray/workspace/tls/ca.crt
                      image: 'quay.io/mmurakam/runtimes:finetuning-ray-runtime-v0.2.2'
                      imagePullPolicy: Always
                      lifecycle:
                        preStop:
                          exec:
                            command:
                              - /bin/sh
                              - '-c'
                              - ray stop
                      name: ray-head
                      ports:
                        - containerPort: 6379
                          name: gcs
                        - containerPort: 8265
                          name: dashboard
                        - containerPort: 10001
                          name: client
                      resources:
                        limits:
                          cpu: 2
                          memory: 2G
                          nvidia.com/gpu: 0
                        requests:
                          cpu: 2
                          memory: 2G
                          nvidia.com/gpu: 0
                      volumeMounts:
                        - mountPath: /models
                          name: models-cache
                  imagePullSecrets: []
                  volumes:
                    - name: models-cache
                      persistentVolumeClaim:
                        claimName: models-cache
            rayVersion: 2.7.0
            workerGroupSpecs:
              - groupName: small-group-llamafinetunelora
                maxReplicas: 1
                minReplicas: 1
                rayStartParams:
                  block: 'true'
                  num-gpus: '1'
                replicas: 1
                template:
                  metadata:
                    annotations:
                      key: value
                    labels:
                      key: value
                  spec:
                    containers:
                      - env:
                          - name: MY_POD_IP
                            valueFrom:
                              fieldRef:
                                fieldPath: status.podIP
                          - name: RAY_USE_TLS
                            value: '0'
                          - name: RAY_TLS_SERVER_CERT
                            value: /home/ray/workspace/tls/server.crt
                          - name: RAY_TLS_SERVER_KEY
                            value: /home/ray/workspace/tls/server.key
                          - name: RAY_TLS_CA_CERT
                            value: /home/ray/workspace/tls/ca.crt
                        image: 'quay.io/mmurakam/runtimes:finetuning-ray-runtime-v0.2.2'
                        lifecycle:
                          preStop:
                            exec:
                              command:
                                - /bin/sh
                                - '-c'
                                - ray stop
                        name: machine-learning
                        resources:
                          limits:
                            cpu: 4
                            memory: 96G
                            nvidia.com/gpu: 1
                          requests:
                            cpu: 4
                            memory: 96G
                            nvidia.com/gpu: 1
                        volumeMounts:
                          - mountPath: /models
                            name: models-cache
                    imagePullSecrets: []
                    volumes:
                      - name: models-cache
                        persistentVolumeClaim:
                          claimName: models-cache
                    initContainers:
                      - command:
                          - sh
                          - '-c'
                          - until nslookup $RAY_IP.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done
                        image: 'busybox:1.28'
                        name: init-myservice
        replicas: 1
      - generictemplate:
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: ray-dashboard-llamafinetunelora
            namespace: ray-demo
          spec:
            rules:
              - host: ray-dashboard-llamafinetunelora-ray-demo.apps.CLUSTER_DOMAIN
                http:
                  paths:
                    - backend:
                        service:
                          name: llamafinetunelora-head-svc
                          port:
                            number: 8265
                      path: /
                      pathType: Prefix
        replicas: 1
